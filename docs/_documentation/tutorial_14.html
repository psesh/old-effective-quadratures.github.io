<!DOCTYPE html>
<html >
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
      <title>Vector-valued dimension reduction</title>
    
      <link rel="stylesheet" href="../_static/pygments.css">
      <link rel="stylesheet" href="../_static/theme.css">
      <link rel="stylesheet" href="../_static/sphinx_press_theme.css">
          <link rel="stylesheet" href="../_static/styles.css" type="text/css" />
      
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>

      <!-- sphinx script_files -->
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

      
      <script src="../_static/theme-vendors.js"></script>
      <script src="../_static/theme.js" defer></script>
    
      <link rel="shortcut icon" href="../_static/eq-logo-favicon.png"/>
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" /> 
  </head>

  <body>
    <div id="app" class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="/" class="home-link">
    
      <img class="logo" src="../_static/logo-5-black-text-lowres.png" alt="logo"/>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



  
    <div class="nav-item">
      <a href="/products/"
        class="nav-link">
          Products
      </a>
    </div>
  
    <div class="nav-item">
      <a href="/about-us/"
        class="nav-link">
          About Us
      </a>
    </div>
  


  
    <div class="nav-item">
      <a href="https://discourse.effective-quadratures.org/"
        class="nav-link external" target="_blank" >
          Blog <outboundlink/>
      </a>
    </div>
  
    <div class="nav-item">
      <a href="https://github.com/Effective-Quadratures"
        class="nav-link external" target="_blank" >
          Github <outboundlink/>
      </a>
    </div>
  

    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



  
    <div class="nav-item">
      <a href="/products/"
        class="nav-link">
          Products
      </a>
    </div>
  
    <div class="nav-item">
      <a href="/about-us/"
        class="nav-link">
          About Us
      </a>
    </div>
  


  
    <div class="nav-item">
      <a href="https://discourse.effective-quadratures.org/"
        class="nav-link external" target="_blank" >
          Blog <outboundlink/>
      </a>
    </div>
  
    <div class="nav-item">
      <a href="https://github.com/Effective-Quadratures"
        class="nav-link external" target="_blank" >
          Github <outboundlink/>
      </a>
    </div>
  

            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="index.html#documentation">documentation</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 "><a href="research.html" class="reference internal ">Research: theory and practice</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="modules.html" class="reference internal ">Modules</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="tutorials.html" class="reference internal ">Tutorials</a>

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
    
    <li>Vector-valued dimension reduction</li>
  </ul>
  

  <ul class="page-nav">
</ul>
  
</div>
<hr>
          <div class="content" role="main">
            
  <div class="section" id="vector-valued-dimension-reduction">
<h1>Vector-valued dimension reduction<a class="headerlink" href="#vector-valued-dimension-reduction" title="Permalink to this headline">Â¶</a></h1>
<p>In some applications, we may be interested in the approximation of vector-valued objectives. This allows us to study the dimension reducing subspaces of multiple scalar objectives, such as the lift and drag of an airfoil simultaneously. Alternatively, we may be interested in the discretized pressure profile over this airfoil. With an approach that extends the technique of <a class="reference external" href="https://effective-quadratures.github.io/Effective-Quadratures/_documentation/tutorial_11.html">active subspaces</a>, and the closely related ridge approximation, we can find subspaces within which the greatest variation of the vector-valued function will be contained. In other words, for a function <span class="math notranslate nohighlight">\(\mathbf{f}(\mathbf{x}): \mathbb{R}^d \rightarrow \mathbb{R}^n\)</span>, we want to find a ridge approximation</p>
<div class="math notranslate nohighlight">
\[\mathbf{f}(\mathbf{x}) \approx \mathbf{g}( \mathbf{U}^T \mathbf{x}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{U} \in \mathbb{R}^{k \times d}\)</span> with <span class="math notranslate nohighlight">\(k \ll d\)</span>. In Effective Quadratures, we base our approach on Zahm et al. [1] and study the vector gradient covariance matrix. Let us define the Jacobian matrix as</p>
<div class="math notranslate nohighlight">
\[\mathbf{J}(\mathbf{x}) = \left[\frac{\partial f_1}{\partial \mathbf{x}} , \frac{\partial f_2}{\partial \mathbf{x}} ,..., \frac{\partial f_n}{\partial \mathbf{x}} \right],\]</div>
<p>where <span class="math notranslate nohighlight">\(f_i\)</span> is the <span class="math notranslate nohighlight">\(i\)</span>-th output component of <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>. This matrix is constructed by stacking together the gradient vectors <span class="math notranslate nohighlight">\(\frac{\partial f_i}{\partial \mathbf{x}}\)</span>.</p>
<p>So, how are the gradients evaluated? Assuming that automatic differentiation utilities or adjoints are not available, we can adopt an approach similar to that detailed in the <a class="reference external" href="https://effective-quadratures.github.io/Effective-Quadratures/_documentation/tutorial_11.html">active subspaces tutorial</a> , and assume that each <span class="math notranslate nohighlight">\(f_i\)</span> has already been approximated as a polynomial series,</p>
<div class="math notranslate nohighlight">
\[f_i(\mathbf{x}) \approx \sum_{j=1}^P a_j \phi_j(\mathbf{x}),\]</div>
<p>from which gradients are easily evaluated. Then, we can form the gradient covariance matrix <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> as</p>
<div class="math notranslate nohighlight">
\[\mathbf{H} = \int \mathbf{J}(\mathbf{x}) \mathbf{R} \mathbf{J}(\mathbf{x})^T \rho(\mathbf{x}) d\mathbf{x}.\]</div>
<p>In this expression, the positive semi-definite matrix <span class="math notranslate nohighlight">\(\mathbf{R}\)</span> represents the weighting of objectives. We can place more weight on some objectives than others, analogous to a weighted objective function derived from multiple objectives in an optimization problem.</p>
<p>We can then compute the eigendecomposition of <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> as in the scalar output case, and retain the eigenvectors corresponding to the largest eigenvalues as the columns of the dimension reducing matrix <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>. A Monte-Carlo based strategy for vector-valued dimension reduction using EQ is then</p>
<ol class="arabic simple">
<li><p>For each component <span class="math notranslate nohighlight">\(f_i(\mathbf{x})\)</span> of the function <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>, we fit a polynomial surrogate, <span class="math notranslate nohighlight">\(f_i(\mathbf{x}) \approx p_i(\mathbf{x}) = \sum_{j=1}^P a_j \phi_j(\mathbf{x})\)</span></p></li>
<li><p>Sample each polynomial at <span class="math notranslate nohighlight">\(M\)</span> points drawn from the input distribution <span class="math notranslate nohighlight">\(\rho(\mathbf{x})\)</span> and evaluate the gradient at each point.</p></li>
<li><p>Form the Jacobian matrix using the polynomial surrogates at each input point, <span class="math notranslate nohighlight">\(\mathbf{J}(\mathbf{x}_i) = \left[\frac{\partial p_1}{\partial \mathbf{x}}(\mathbf{x}_i) , \frac{\partial p_2}{\partial \mathbf{x}} (\mathbf{x}_i),..., \frac{\partial p_n}{\partial \mathbf{x}}  (\mathbf{x}_i)\right]\)</span> for <span class="math notranslate nohighlight">\(i = 1,...,M\)</span>.</p></li>
<li><p>Evaluate the vector gradient covariance matrix with a prescribed <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>,</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\mathbf{H} = \frac{1}{M}\sum_{i=1}^M \mathbf{J}(\mathbf{x}_i) \mathbf{R} \mathbf{J}(\mathbf{x}_i)^T\]</div>
<ol class="arabic simple" start="5">
<li><p>Compute the eigendecomposition of <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> and partition the eigenvectors with large eigenvalues to obtain <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{H} = [\mathbf{U}\quad \mathbf{V}] \begin{bmatrix} \mathbf{\Lambda}_1 &amp; \\ &amp; \mathbf{\Lambda}_2 \end{bmatrix} [\mathbf{U} \quad \mathbf{V}]^T,\end{split}\]</div>
<p><strong>Code Implementation</strong></p>
<p>We consider a simple analytical example to demonstrate the use of our vector-valued dimension reduction routines. Consider the function <span class="math notranslate nohighlight">\(\mathbf{f}: [-1,1]^5 \rightarrow \mathbb{R}^2\)</span>, with <span class="math notranslate nohighlight">\(\mathbf{f}(\mathbf{x}) = [f_0(\mathbf{x}), f_1(\mathbf{x})]^T\)</span> where:</p>
<div class="math notranslate nohighlight">
\[f_0(\mathbf{x}) = \sin(\pi \mathbf{w}_0^T \mathbf{x})\]</div>
<div class="math notranslate nohighlight">
\[f_1(\mathbf{x}) = \exp(\mathbf{w}_1^T \mathbf{x})\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">equadratures</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">def</span> <span class="nf">f_0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">))</span>
</pre></div>
</div>
<p>We define <span class="math notranslate nohighlight">\(\mathbf{W} = [\mathbf{w}_0, \mathbf{w}_1]\)</span> as random orthogonal vectorsâ¦</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rand_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
<span class="n">W</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">rand_norm</span><span class="p">)</span>
</pre></div>
</div>
<p>and use 1000 samples to construct seventh-degree polynomials for the component functions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">poly_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">myBasis</span> <span class="o">=</span> <span class="n">Basis</span><span class="p">(</span><span class="s1">&#39;Total order&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">)])</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">Parameter</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">)]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">Y_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">f_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">Y_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">f_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="n">poly_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Polyreg</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">myBasis</span><span class="p">,</span> <span class="n">training_inputs</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">training_outputs</span><span class="o">=</span><span class="n">Y_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span>
                        <span class="n">no_of_quad_points</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p>Now we can call the <code class="code docutils literal notranslate"><span class="pre">vector_AS</span></code> method in the <code class="code docutils literal notranslate"><span class="pre">dr</span></code> class to compute the Jacobian and find the dimension reducing subspace <span class="math notranslate nohighlight">\(\mathbf{U}\)</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">my_dr</span> <span class="o">=</span> <span class="n">dr</span><span class="p">(</span><span class="n">training_input</span><span class="o">=</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="p">[</span><span class="n">eigs</span><span class="p">,</span> <span class="n">U</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_dr</span><span class="o">.</span><span class="n">vector_AS</span><span class="p">(</span><span class="n">poly_list</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="n">R</span><span class="p">)</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
</pre></div>
</div>
<p>To verify whether our answer is reasonable, we can check the subspace distance between <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> and the space spanned by the true dimension reducing subspace, <span class="math notranslate nohighlight">\(\text{span}(\mathbf{w}_0, \mathbf{w}_1)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{dist}(\mathbf{U}, \mathbf{W}) = ||\mathbf{U}\mathbf{U}^T - \mathbf{W}\mathbf{W}^T||_2\]</div>
<p>where the 2-norm picks out the largest singular value of the argument.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">subspace_dist</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">B</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">subspace_dist</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">U</span><span class="p">[:,:</span><span class="n">n</span><span class="p">])))</span>
</pre></div>
</div>
<p>We can also verify that the variation of both functions outside of <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> is small. Here, for each of 10 sets of active coordinates, we sample 50 points in the inactive subspace (<span class="math notranslate nohighlight">\(\mathbf{V}\)</span>) using the âhit and runâ algorithm from Python Active-subspaces Utility Library [2].</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">active_subspaces.domains</span> <span class="kn">import</span> <span class="n">hit_and_run_z</span>
<span class="k">def</span> <span class="nf">harz</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">N</span><span class="p">):</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">W1</span><span class="p">,</span><span class="n">W2</span><span class="p">])</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">hit_and_run_z</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span>
        <span class="n">yz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">N</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">yz</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">N_inactive</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">plot_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N_inactive</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">rand_active_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">new_X</span> <span class="o">=</span> <span class="n">harz</span><span class="p">(</span><span class="n">U</span><span class="p">[:,:</span><span class="n">n</span><span class="p">],</span> <span class="n">U</span><span class="p">[:,</span><span class="n">n</span><span class="p">:],</span> <span class="n">rand_active_coords</span><span class="p">,</span> <span class="n">N_inactive</span><span class="p">)</span>

        <span class="n">new_f0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">f_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">new_X</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">new_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="n">f_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">new_X</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">plot_coords</span><span class="p">[:,</span><span class="mi">0</span><span class="p">,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_f0</span>
        <span class="n">plot_coords</span><span class="p">[:,</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_f1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">plot_coords</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">],</span> <span class="n">plot_coords</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/inactive.png"><img alt="../_images/inactive.png" src="../_images/inactive.png" style="width: 640.0px; height: 480.0px;" /></a>
</div>
<p>It can be seen that at each active coordinate, the variation in the inactive subspace is small.</p>
<p><strong>References</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p>Zahm, O.,  Constantine, P., Prieur, C. and Marzouk, Y., (2018). Gradient-based dimension reduction of multi-variate vector-valued functions. <a class="reference external" href="http://arxiv.org/abs/1801.07922">Preprint</a></p>
</dd>
<dt class="label" id="id2"><span class="brackets">2</span></dt>
<dd><p>Constantine, P., Howard, R., Glaws, A., Grey, Z., Diaz, P., &amp; Fletcher, L. (2016). Python Active-subspaces Utility Library. Zenodo. <a class="reference external" href="http://doi.org/10.5281/zenodo.158941">Code</a></p>
</dd>
</dl>
</div>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2016-2020 by Effective Quadratures.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a>.
</div>
            </div>
          </div>
      </page>
    </div>
    
    
  </body>
</html>